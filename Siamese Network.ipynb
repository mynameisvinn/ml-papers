{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10/30/20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0UL7xKBso8Pm"
   },
   "outputs": [],
   "source": [
    "from os import walk\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from torchsummary import summary\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vY_FtijPo8Pt"
   },
   "outputs": [],
   "source": [
    "# setting the root directories and categories of the images\n",
    "root_dir = './images_background/'\n",
    "# root_dir = './images_evaluation/'\n",
    "categories = [[folder, os.listdir(root_dir + folder)] for folder in os.listdir(root_dir)  if not folder.startswith('.') ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "khIHVwcLo8Px"
   },
   "outputs": [],
   "source": [
    "# creating the pairs of images for inputs, same character label = 1, vice versa\n",
    "class OmniglotDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, categories, root_dir, setSize, transform=None):\n",
    "        self.categories = categories\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.setSize = setSize\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.setSize\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img1 = None\n",
    "        img2 = None\n",
    "        label = None\n",
    "        \n",
    "        if idx % 2 == 0: # select two examples of the same character\n",
    "            category = random.choice(categories)  # a category is the alphabet\n",
    "            character = random.choice(category[1])  # character is the character, so the english alphabet has 26 characters\n",
    "            \n",
    "            # pick two random examples of a given character in this alphabet\n",
    "            imgDir = root_dir + category[0] + '/' + character  \n",
    "            img1Name = random.choice(os.listdir(imgDir))\n",
    "            img2Name = random.choice(os.listdir(imgDir))\n",
    "            img1 = Image.open(imgDir + '/' + img1Name)\n",
    "            img2 = Image.open(imgDir + '/' + img2Name)\n",
    "\n",
    "            label = 1.0\n",
    "            \n",
    "        else: # select a different character for both images\n",
    "            category1, category2 = random.choice(categories), random.choice(categories)\n",
    "            character1, character2 = random.choice(category1[1]), random.choice(category2[1])\n",
    "            imgDir1, imgDir2 = root_dir + category1[0] + '/' + character1, root_dir + category2[0] + '/' + character2\n",
    "            img1Name = random.choice(os.listdir(imgDir1))\n",
    "            img2Name = random.choice(os.listdir(imgDir2))\n",
    "            while img1Name == img2Name:\n",
    "                img2Name = random.choice(os.listdir(imgDir2))\n",
    "            label = 0.0\n",
    "            img1 = Image.open(imgDir1 + '/' + img1Name)\n",
    "            img2 = Image.open(imgDir2 + '/' + img2Name)\n",
    "#         plt.imshow(img1)\n",
    "        if self.transform:\n",
    "            img1 = self.transform(img1)\n",
    "            img2 = self.transform(img2)\n",
    "        return img1, img2, torch.from_numpy(np.array([label], dtype=np.float32))          \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fMqRspJ9UEbW"
   },
   "outputs": [],
   "source": [
    "# creates n-way one shot learning evaluation\n",
    "class NWayOneShotEvalSet(Dataset):\n",
    "    def __init__(self, categories, root_dir, setSize, numWay, transform=None):\n",
    "        self.categories = categories\n",
    "        self.root_dir = root_dir\n",
    "        self.setSize = setSize\n",
    "        self.numWay = numWay\n",
    "        self.transform = transform\n",
    "    def __len__(self):\n",
    "        return self.setSize\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # find one main image\n",
    "        category = random.choice(categories)  # which alphabet do we want to go with\n",
    "        character = random.choice(category[1])  # which letter/character in the alphabet do we want to look at\n",
    "        imgDir = root_dir + category[0] + '/' + character  # now we've decided on a specific letter in a specific alphabet\n",
    "        imgName = random.choice(os.listdir(imgDir))  # randomly choose an exammple as our main image\n",
    "        mainImg = Image.open(imgDir + '/' + imgName)\n",
    "\n",
    "        if self.transform:\n",
    "            mainImg = self.transform(mainImg)\n",
    "        \n",
    "        # find n numbers of distinct images, 1 in the same set as the main\n",
    "        testSet = []  # the main image is compared against this list of TestSet\n",
    "        label = np.random.randint(self.numWay)  # numway represents number of alphabets we want to compare to\n",
    "        \n",
    "        for i in range(self.numWay):  # how many examples (each example is a unique alphabet) do we get to use\n",
    "            testImgDir = imgDir\n",
    "            testImgName = ''\n",
    "            \n",
    "            # we want at least one example from the same letter of the same alphabet in the testset\n",
    "            if i == label:  \n",
    "                testImgName = random.choice(os.listdir(imgDir))\n",
    "            \n",
    "            # all other examples should come from other alphabets/characters\n",
    "            else:\n",
    "                testCategory = random.choice(categories)  # now we choose another random category\n",
    "                testCharacter = random.choice(testCategory[1])  # with another random letter from that alphabet\n",
    "                testImgDir = root_dir + testCategory[0] + '/' + testCharacter\n",
    "                while testImgDir == imgDir:\n",
    "                    testImgDir = root_dir + testCategory[0] + '/' + testCharacter\n",
    "                testImgName = random.choice(os.listdir(testImgDir))  # with a random example\n",
    "            \n",
    "            testImg = Image.open(testImgDir + '/' + testImgName)\n",
    "            \n",
    "            if self.transform:\n",
    "                testImg = self.transform(testImg)\n",
    "            \n",
    "            testSet.append(testImg)\n",
    "        # plt.imshow()\n",
    "        return mainImg, testSet, torch.from_numpy(np.array([label], dtype = int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fxY8faBco8P0"
   },
   "outputs": [],
   "source": [
    "# choose a training dataset size and further divide it into train and validation set 80:20\n",
    "dataSize = 10000 # self-defined dataset size\n",
    "TRAIN_PCT = 0.8 # percentage of entire dataset for training\n",
    "train_size = int(dataSize * TRAIN_PCT)\n",
    "val_size = dataSize - train_size\n",
    "\n",
    "transformations = transforms.Compose([transforms.ToTensor()]) \n",
    "\n",
    "omniglotDataset = OmniglotDataset(categories, root_dir, dataSize, transformations)\n",
    "train_set, val_set = random_split(omniglotDataset, [train_size, val_size])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=128, num_workers=16)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(val_set, batch_size=1, num_workers=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2LYX5Fk-mp5b"
   },
   "outputs": [],
   "source": [
    "# create the test set for final testing\n",
    "testSize = 5000 \n",
    "numWay = 20  # how many alphabets? the more unseen alphabets, the more difficult it is to match examples\n",
    "test_set = NWayOneShotEvalSet(categories, root_dir, testSize, numWay, transformations)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size = 1, num_workers = 2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 568
    },
    "colab_type": "code",
    "id": "9ymZBJfVo8P5",
    "outputId": "785b1c17-7c8f-4ee2-b898-7f146b390833"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tensor([[[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         ...,\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.]]])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# showing a sample input of a training set\n",
    "for img1, img2, label in train_loader:\n",
    "    print()\n",
    "    if label[0] == 1.0:\n",
    "        print(img1[0])\n",
    "        plt.subplot(1,2,1)\n",
    "        plt.imshow(img1[0][0])\n",
    "        plt.subplot(1,2,2)\n",
    "        plt.imshow(img2[0][0])\n",
    "        # print(label)\n",
    "        break\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 379
    },
    "colab_type": "code",
    "id": "Q9Dagxfc-geN",
    "outputId": "3bb3883a-2caf-4d77-a305-61d4885970f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 105, 105])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 21 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# showing a sample input of the testing set\n",
    "count = 0\n",
    "for mainImg, imgset, label in test_loader:\n",
    "    # print(len(imgset))\n",
    "    # print(label)\n",
    "    # print(imgset.shape)\n",
    "    if label != 1:\n",
    "        for count, img in enumerate(imgset):\n",
    "          plt.subplot(1, len(imgset)+1, count+1)\n",
    "          plt.imshow(img[0][0])\n",
    "          # print(img.shape)\n",
    "        print(mainImg.shape)\n",
    "        plt.subplot(1, len(imgset)+1, len(imgset)+1)\n",
    "        plt.imshow(mainImg[0][0])\n",
    "        count += 1\n",
    "        break\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MuoDdu_Ao8P3"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BPdWGiEeo8P9"
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        # Koch et al.\n",
    "        # Conv2d(input_channels, output_channels, kernel_size)\n",
    "        self.conv1 = nn.Conv2d(1, 64, 10)  # go from a single channel to 64 channels\n",
    "        self.conv2 = nn.Conv2d(64, 128, 7)  \n",
    "        self.conv3 = nn.Conv2d(128, 128, 4)\n",
    "        self.conv4 = nn.Conv2d(128, 256, 4)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.bn2 = nn.BatchNorm2d(128)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.bn4 = nn.BatchNorm2d(256)\n",
    "        self.dropout1 = nn.Dropout(0.1)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(256 * 6 * 6, 4096)\n",
    "        self.fcOut = nn.Linear(4096, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    \n",
    "    def convs(self, x):\n",
    "\n",
    "        # Koch et al.\n",
    "        # out_dim = in_dim - kernel_size + 1  \n",
    "        #1, 105, 105\n",
    "        x = F.relu(self.bn1(self.conv1(x)))  # starting with 1x105x105 image, x becomes 64x96x96\n",
    "        x = F.max_pool2d(x, (2,2))  # 64x96x96 turns into 64x48x48\n",
    "        x = F.relu(self.bn2(self.conv2(x)))  #64x48x48 turns into 128x42x42\n",
    "        x = F.max_pool2d(x, (2,2))  # 128x42x42 turns into 128x21x21\n",
    "        x = F.relu(self.bn3(self.conv3(x)))  # 128x21x21 turns into 128x18x18\n",
    "        x = F.max_pool2d(x, (2,2))  # 128x18x18 turns into 128x9x9\n",
    "        x = F.relu(self.bn4(self.conv4(x)))  # 128x9x9 turns into 256x6x6\n",
    "        return x\n",
    "    \n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.convs(x1)\n",
    "\n",
    "        # Koch et al.\n",
    "        x1 = x1.view(-1, 256 * 6 * 6)\n",
    "        x1 = self.sigmoid(self.fc1(x1))\n",
    "        \n",
    "        x2 = self.convs(x2)  # notice we use the same network\n",
    "        x2 = x2.view(-1, 256 * 6 * 6)\n",
    "        x2 = self.sigmoid(self.fc1(x2))\n",
    "\n",
    "        # the outputs for img1 and img2 are \"merged\" by taking the absolute difference\n",
    "        x = torch.abs(x1 - x2)\n",
    "        x = self.fcOut(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 345
    },
    "colab_type": "code",
    "id": "YNc_GPvDo8QA",
    "outputId": "f95be039-00f1-4d66-dc4d-77e4ba315066"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model architecture:\n",
      "\n",
      " Net(\n",
      "  (conv1): Conv2d(1, 64, kernel_size=(10, 10), stride=(1, 1))\n",
      "  (conv2): Conv2d(64, 128, kernel_size=(7, 7), stride=(1, 1))\n",
      "  (conv3): Conv2d(128, 128, kernel_size=(4, 4), stride=(1, 1))\n",
      "  (conv4): Conv2d(128, 256, kernel_size=(4, 4), stride=(1, 1))\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (bn4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (dropout1): Dropout(p=0.1, inplace=False)\n",
      "  (dropout2): Dropout(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=9216, out_features=4096, bias=True)\n",
      "  (fcOut): Linear(in_features=4096, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n",
      "\n",
      "The model has 38,952,897 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "#creating the original network and couting the paramenters of different networks\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "siameseBaseLine = Net()\n",
    "siameseBaseLine = siameseBaseLine.to(device)\n",
    "\n",
    "def count_parameters(model):\n",
    "    temp = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(f'The model architecture:\\n\\n', model)\n",
    "    print(f'\\nThe model has {temp:,} trainable parameters')\n",
    "    \n",
    "count_parameters(siameseBaseLine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iYRNmrYlo8QC"
   },
   "outputs": [],
   "source": [
    "# saving and loading checkpoint mechanisms\n",
    "def save_checkpoint(save_path, model, optimizer, val_loss):\n",
    "    if save_path==None:\n",
    "        return\n",
    "    save_path = save_path \n",
    "    state_dict = {'model_state_dict': model.state_dict(),\n",
    "                  'optimizer_state_dict': optimizer.state_dict(),\n",
    "                  'val_loss': val_loss}\n",
    "\n",
    "    torch.save(state_dict, save_path)\n",
    "\n",
    "    print(f'Model saved to ==> {save_path}')\n",
    "\n",
    "def load_checkpoint(model, optimizer):\n",
    "    save_path = f'siameseNet-batchnorm50.pt'\n",
    "    state_dict = torch.load(save_path)\n",
    "    model.load_state_dict(state_dict['model_state_dict'])\n",
    "    optimizer.load_state_dict(state_dict['optimizer_state_dict'])\n",
    "    val_loss = state_dict['val_loss']\n",
    "    print(f'Model loaded from <== {save_path}')\n",
    "    \n",
    "    return val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N5378uY-o8QF"
   },
   "outputs": [],
   "source": [
    "# training and validation after every epoch\n",
    "def train(model, train_loader, val_loader, num_epochs, criterion, save_name):\n",
    "    \n",
    "    best_val_loss = float(\"Inf\") \n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    cur_step = 0\n",
    "    \n",
    "    for epoch in range(num_epochs):  # number of passes through training dataset\n",
    "        running_loss = 0.0\n",
    "        model.train()\n",
    "        print(\"Starting epoch \" + str(epoch+1))\n",
    "        for img1, img2, labels in train_loader:\n",
    "            \n",
    "            # Forward\n",
    "            img1 = img1.to(device)\n",
    "            img2 = img2.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(img1, img2)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        avg_train_loss = running_loss / len(train_loader)\n",
    "        train_losses.append(avg_train_loss)\n",
    "        \n",
    "        val_running_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            model.eval()  # switch to eval() since there are dropout and batchnorm layers in the model\n",
    "            for img1, img2, labels in val_loader:\n",
    "                img1 = img1.to(device)\n",
    "                img2 = img2.to(device)\n",
    "                labels = labels.to(device)\n",
    "                outputs = model(img1, img2)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_running_loss += loss.item()\n",
    "        avg_val_loss = val_running_loss / len(val_loader)\n",
    "        val_losses.append(avg_val_loss)\n",
    "        \n",
    "        print('Epoch [{}/{}],Train Loss: {:.4f}, Valid Loss: {:.8f}'.format(epoch+1, num_epochs, avg_train_loss, avg_val_loss))\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            save_checkpoint(save_name, model, optimizer, best_val_loss)\n",
    "    \n",
    "    print(\"Finished Training\")  \n",
    "    return train_losses, val_losses  \n",
    "\n",
    "# evaluation metrics\n",
    "def eval(model, test_loader):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        print('Starting Iteration')\n",
    "        count = 0\n",
    "        for mainImg, imgSets, label in test_loader:\n",
    "            mainImg = mainImg.to(device)\n",
    "            predVal = 0\n",
    "            pred = -1\n",
    "            \n",
    "            # go through each image in testsets (there are 20), lets find the image with the highest similarity\n",
    "            for i, testImg in enumerate(imgSets):\n",
    "                testImg = testImg.to(device)\n",
    "                output = model(mainImg, testImg)\n",
    "                if output > predVal:\n",
    "                    pred = i\n",
    "                    predVal = output\n",
    "            label = label.to(device)\n",
    "            if pred == label:\n",
    "                correct += 1\n",
    "            count += 1\n",
    "            if count % 20 == 0:\n",
    "                print(\"Current Count is: {}\".format(count))\n",
    "                print('Accuracy on n way: {}'.format(correct/count))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "F3OAaokOo8QH",
    "outputId": "3d425e7b-6fc4-4b58-e448-c25e03b37441"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1\n"
     ]
    }
   ],
   "source": [
    "# actual training\n",
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(siameseBaseLine.parameters(), lr = 0.0006)\n",
    "num_epochs = 50\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "save_path = 'siameseNet-batchnorm50.pt'\n",
    "train_losses, val_losses = train(siameseBaseLine, train_loader, val_loader, num_epochs, criterion, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 138
    },
    "colab_type": "code",
    "id": "gCyOZi-NQKPx",
    "outputId": "99335258-7957-4816-81a7-b8367c829369"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from <== siameseNet-batchnorm50.pt\n",
      "0.06619010965561553\n",
      "Starting Iteration\n",
      "Current Count is: 20\n",
      "Accuracy on n way: 0.75\n",
      "Current Count is: 40\n",
      "Accuracy on n way: 0.8\n"
     ]
    }
   ],
   "source": [
    "# Evaluation on previously saved models\n",
    "import torch.optim as optim\n",
    "load_model = Net().to(device)\n",
    "load_optimizer = optim.Adam(load_model.parameters(), lr=0.0006)\n",
    "\n",
    "\n",
    "num_epochs = 10\n",
    "eval_every = 1000\n",
    "total_step = len(train_loader)*num_epochs\n",
    "best_val_loss = load_checkpoint(load_model, load_optimizer)\n",
    "\n",
    "print(best_val_loss)\n",
    "eval(load_model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "colab_type": "code",
    "id": "jT_RTDmso8QI",
    "outputId": "4304ca8a-7590-43af-a1af-0ebfdc9ec93f"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plotting of training and validation loss\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(val_losses, label=\"Validation Loss\")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1.0), loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pXDsPIkvIpQh"
   },
   "outputs": [],
   "source": [
    "\"\"\"How to use the evaluation n way:\n",
    "\n",
    "# Set the parameters\n",
    "testSize = 5000 # how big you want your test size to be\n",
    "numWay = 4 # how many ways metric\n",
    "\n",
    "# Create the dataset for it and put it into dataloader\n",
    "test_set = NWayOneShotEvalSet(categories, root_dir, testSize, numWay, transformations) \n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size = 1, num_workers = 2)\n",
    "\n",
    "\n",
    "# Load the models (the name of the loaded model can be changed in the load_checkpoint() function)\n",
    "load_model = Net().to(device)\n",
    "load_optimizer = optim.Adam(load_model.parameters(), lr=0.0006)\n",
    "\n",
    "\n",
    "num_epochs = 10\n",
    "eval_every = 1000\n",
    "total_step = len(train_loader)*num_epochs\n",
    "best_val_loss = load_checkpoint(load_model, load_optimizer)\n",
    "\n",
    "print(best_val_loss)\n",
    "\n",
    "# Evaluate from the test loader \n",
    "\n",
    "eval(load_model, test_loader)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9xPtPhnTkplG"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "siamese.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
