{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error as mse\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"ggplot\")\n",
    "%matplotlib inline\n",
    "\n",
    "def generate_points(k):\n",
    "    \"\"\"sample x,y examples from a randomly initialized sine curve.\n",
    "    \"\"\"\n",
    "    n_points = 100\n",
    "    \n",
    "    phase = np.random.uniform(low=0, high=2*np.pi)\n",
    "    ampl = np.random.uniform(low=0.1, high=5)\n",
    "    X = np.linspace(-5, 5, n_points)\n",
    "    y = np.sin(X + phase) * ampl\n",
    "    \n",
    "\n",
    "    keys = np.random.choice(np.arange(n_points), size=k)\n",
    "    return (X[keys], y[keys], X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a simple model\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "n_hidden = 64\n",
    "n_classes = 1\n",
    "n_features = 1\n",
    "\n",
    "X_ = tf.placeholder(tf.float32, shape=[None, n_features])\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, n_classes])\n",
    "\n",
    "with tf.variable_scope(\"parameters\"):\n",
    "    w1 = tf.Variable(tf.random_uniform([n_features, n_hidden]))\n",
    "    b1 = tf.Variable(tf.random_uniform([n_hidden]))\n",
    "    w2 = tf.Variable(tf.random_uniform([n_hidden, n_hidden]))\n",
    "    b2 = tf.Variable(tf.random_uniform([n_hidden]))\n",
    "    w3 = tf.Variable(tf.random_uniform([n_hidden, n_classes]))\n",
    "    b3 = tf.Variable(tf.random_uniform([n_classes]))\n",
    "\n",
    "with tf.variable_scope(\"model\"):\n",
    "    z1 = tf.matmul(X_, w1) + b1\n",
    "    fc1 = tf.nn.tanh(z1)\n",
    "    z2 = tf.matmul(fc1, w2) + b2\n",
    "    fc2 = tf.nn.tanh(z2)\n",
    "    z3 = tf.matmul(fc2, w3) + b3\n",
    "\n",
    "loss = tf.reduce_mean(tf.square(z3 - y_))\n",
    "op = tf.train.AdamOptimizer(1e-2).minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, loss 721.898\n",
      "epoch 100, loss 1.986\n",
      "epoch 200, loss 1.599\n",
      "epoch 300, loss 0.694\n",
      "epoch 400, loss 0.048\n",
      "epoch 500, loss 8.748\n",
      "epoch 600, loss 2.105\n",
      "epoch 700, loss 9.819\n",
      "epoch 800, loss 0.674\n",
      "epoch 900, loss 0.806\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "# lets pretrain to find a good initialization parameters\n",
    "\n",
    "n_tasks = 1000  # number of tasks (eg sine curves), should be at least 10000\n",
    "n_examples = 50  # number of examples per task; reptile uses 50 examples per task\n",
    "mb_size = 10  # reptile uses mb size of 10\n",
    "n_epochs = 5  # k > 1  # we can train as much as we'd like\n",
    "save_path = \"model/reptile.ckpt\"\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    # randomly sample a task from p(Tasks)...\n",
    "    for task in range(n_tasks):\n",
    "        \n",
    "        # collect old parameters\n",
    "        w1_a, b1_a, w2_a, b2_a, w3_a, b3_a = sess.run([w1, b1, w2, b2, w3, b3])\n",
    "        \n",
    "        # fetch x,y examples from that task\n",
    "        xs, ys, _, _ = generate_points(n_examples)\n",
    "    \n",
    "        # parameter update\n",
    "        for _ in range(n_epochs):\n",
    "            \n",
    "            # minibatch update\n",
    "            for start in range(0, n_examples, mb_size):\n",
    "                xs_b = xs[start:start+mb_size]\n",
    "                ys_b = ys[start:start+mb_size]\n",
    "                _ = sess.run(op, feed_dict={X_: xs_b.reshape(mb_size,1), \n",
    "                                            y_: ys_b.reshape(mb_size,1)})\n",
    "        \n",
    "        # collect new parameters\n",
    "        w1_b, b1_b, w2_b, b2_b, w3_b, b3_b = sess.run([w1, b1, w2, b2, w3, b3])\n",
    "        \n",
    "        # calculate \"meta gradient\"\n",
    "        outerstepsize = .1 * (1 - task / n_tasks)\n",
    "        w1_c = w1_a + (w1_b - w1_a) * outerstepsize\n",
    "        b1_c = b1_a + (b1_b - b1_a) * outerstepsize\n",
    "        \n",
    "        w2_c = w2_a + (w2_b - w2_a) * outerstepsize\n",
    "        b2_c = b2_a + (b2_b - b2_a) * outerstepsize\n",
    "        \n",
    "        w3_c = w3_a + (w3_b - w3_a) * outerstepsize\n",
    "        b3_c = b3_a + (b3_b - b3_a) * outerstepsize\n",
    "        \n",
    "        # update model with new parameters\n",
    "        w1.load(w1_c, sess)\n",
    "        b1.load(b1_c, sess)\n",
    "        w2.load(w2_c, sess)\n",
    "        b2.load(b2_c, sess)\n",
    "        w3.load(w3_c, sess)\n",
    "        b3.load(b3_c, sess)\n",
    "        \n",
    "        # calculate loss\n",
    "        if task % (n_tasks / 10) == 0:\n",
    "            loss_ = sess.run(loss, feed_dict={X_: xs.reshape(n_examples,1), y_: ys.reshape(n_examples,1)})\n",
    "            print(\"epoch {}, loss {:.3f}\".format(task, loss_))\n",
    "    \n",
    "    saver.save(sess, save_path, global_step=task)\n",
    "\n",
    "print(\"done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare performance between (a) randomly initialized network versus (b) pretrained network\n",
    "\n",
    "n_examples = 20  # we only get a few examples (1-5) for each task\n",
    "n_epochs = 50  # we also want to be be quick, only a few steps\n",
    "xs, ys, xf, yf = generate_points(n_examples)  # generate a single set of xy so we can compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, lets see how well a randomly initalized model would do on new tasks\n",
    "\n",
    "with tf.Session() as sess3:\n",
    "    sess3.run(init)\n",
    "        \n",
    "    for _ in range(n_epochs):\n",
    "        _ = sess3.run(op, feed_dict={X_: xs.reshape(n_examples,1), \n",
    "                                     y_: ys.reshape(n_examples,1)})\n",
    "\n",
    "    # calculate predictions on the entire dataset\n",
    "    y_pred_random = sess3.run(z3, feed_dict={X_: xs.reshape(n_examples,1)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from model/reptile.ckpt-49999\n"
     ]
    }
   ],
   "source": [
    "# then, lets use a well initialized/conditioned network - it should be able to learn from a few examples\n",
    "with tf.Session() as sess2:\n",
    "    sess2.run(init)\n",
    "    \n",
    "    # restore model\n",
    "    ckpt_folder = tf.train.get_checkpoint_state(\"model\")\n",
    "    load_path = ckpt_folder.model_checkpoint_path\n",
    "    saver.restore(sess2, load_path)\n",
    "\n",
    "    for _ in range(n_epochs):\n",
    "        _ = sess2.run(op, feed_dict={X_: xs.reshape(n_examples,1), y_: ys.reshape(n_examples,1)})\n",
    "    y_pred_initialized = sess2.run(z3, feed_dict={X_: xs.reshape(n_examples,1)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a well-initialized network can learn from a few examples\n",
    "plt.scatter(xs, y_pred_random, color ='g')  # random\n",
    "plt.scatter(xs, y_pred_initialized, color ='b', marker=\"*\", s=202)  # initialized\n",
    "plt.plot(xf, yf, linewidth=2, color='r', linestyle='--')  # true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
